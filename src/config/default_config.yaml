# Default Configuration for YorK_RP Active Inference Circuit Discovery
# This file contains the default parameters for all experiment components

model:
  name: "gpt2-small"
  device: "auto"  # auto, cpu, cuda
  max_context_length: 1024
  use_cache: true

sae:
  enabled: true
  auto_discover_layers: true      # Auto-discover active layers instead of forcing targets
  target_layers: []               # Empty - will be populated by auto-discovery
  activation_threshold: 0.05
  max_features_per_layer: 20
  neuronpedia_source: true
  layer_search_range: [0, -1]     # Search all layers: [start, end] (-1 = last layer)
  sample_inputs_for_layer_discovery:
    - "The Golden Gate Bridge is located in"
    - "When I think about cats, I"
    - "The capital of France is"
  auto_discover_min_layers: 6
  auto_discover_max_layers: 8
  auto_discover_layer_ratio: 0.5
  fallback_sae_feature_multiplier: 4
  fallback_sae_weight_scale: 0.1

active_inference:
  enabled: true
  epistemic_weight: 0.7
  exploration_weight: 0.6
  convergence_threshold: 0.15
  max_interventions: 20
  use_pymdp: true
  baseline_intervention_multiplier: 3.0
  baseline_convergence_std_threshold: 0.05
  baseline_convergence_recent_effects_count: 5

experiment:
  name: "golden_gate_bridge_discovery"
  output_dir: "experiment_results"
  max_parallel_jobs: 1
  save_intermediate_results: true
  generate_visualizations: true

research_questions:
  rq1_correspondence_target: 70.0  # Percentage
  rq2_efficiency_target: 30.0      # Percentage improvement  
  rq3_predictions_target: 3        # Number of validated predictions
  prediction_validation_confidence_threshold: 0.7

logging:
  level: "INFO"
  file_output: true
  console_output: true
  max_file_size_mb: 10
