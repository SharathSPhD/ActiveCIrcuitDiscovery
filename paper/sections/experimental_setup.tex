\subsection{Models and Hardware}

The framework is evaluated on two transformer architectures:
\begin{itemize}
\item \textbf{Gemma-2-2B}~\cite{team2024gemma}: 26 layers, 2304-dim,
  8 heads.  Transcoders from GemmaScope
  (\texttt{mwhanna/gemma-scope-transcoders}).
\item \textbf{Llama-3.2-1B}~\cite{Dubey2024llama}: 16 layers, 2048-dim,
  32 heads with GQA.  Transcoders from
  \texttt{mntss/transcoder-Llama-3.2-1B}.
\end{itemize}
Both models use the \texttt{circuit-tracer} library~\cite{Anthropic2025CT}
with the TransformerLens backend for attribution graph construction
and transcoder-level interventions.

Experiments run on an NVIDIA DGX Spark with GB10 GPU (128\,GB unified
memory, CUDA 12.8, aarch64).  Colab notebooks reproduce results on a
free T4 GPU.

\subsection{Benchmarks}

\subsubsection{IOI Circuit Recovery}

The Indirect Object Identification task, introduced by
Wang et al.~\cite{Wang2022}, tests whether the agent can identify
features causally responsible for predicting the indirect object.
Five prompts of the form
``When [A] and [B] went to the store, [A] gave the bag to \_\_''
are used, where the correct prediction is [B].  For each prompt,
the KL divergence caused by ablating each candidate feature via the
\texttt{feature\_intervention} API is measured.

\subsubsection{Multi-step Reasoning}

Three prompts requiring compositional reasoning across two or more
hops: e.g.\ ``The capital of the country where the Eiffel Tower is
located is''.

\subsubsection{Feature Steering}

Five concept prompts (Golden Gate Bridge, Eiffel Tower, Mount Everest,
Great Wall of China, Statue of Liberty).
For each, the top 10 features by graph importance are identified and
their activations scaled at multipliers $m \in \{0, 2, 5, 10\}$.
The KL divergence and whether the model's top prediction changes
are measured.

\subsubsection{Multi-Domain Benchmark}

Following the Initial Research Proposal, the framework is evaluated
across five cognitive domains with two prompts each:
\begin{itemize}
\item \textbf{Geography}: ``The capital of France is'', ``The Golden Gate Bridge connects San Francisco to''
\item \textbf{Mathematics}: ``The square root of 64 is'', ``If 2 + 3 = 5 then 3 + 4 =''
\item \textbf{Science}: ``Water is made of hydrogen and'', ``The speed of light is approximately''
\item \textbf{Logic}: syllogistic reasoning (``All mammals are warm-blooded\ldots'')
\item \textbf{History}: ``The year World War II ended was'', ``The first person to walk on the moon was''
\end{itemize}
This allows cross-domain comparison of circuit structure and layer
distribution.

\subsection{Baselines}

\begin{itemize}
\item \textbf{Random:} Features are selected uniformly at random (10 trials,
  results averaged).
\item \textbf{Greedy:} Features are selected in descending order of graph
  node influence (sum of absolute adjacency weights).
\item \textbf{Bandit:} A UCB-style heuristic selector that combines
  graph importance with a decaying uncertainty bonus and learned
  per-layer priors. This provides a comparison point that separates
  the contribution of Active Inference from simpler uncertainty
  heuristics.
\item \textbf{Oracle:} Features are selected in descending order of
  true KL divergence (upper bound requiring all ablations in advance).
\end{itemize}

All methods use the same \texttt{feature\_intervention} API and
KL divergence metric.  Budgets are fixed at $B=20$ interventions
per prompt.

\subsection{Metrics}

\begin{itemize}
\item \textbf{Mean KL per intervention:}  Average KL divergence across
  selected features.  Higher values indicate the method finds more
  causally important features.

\item \textbf{Cumulative KL:}  Total information gained over the
  budget.  Compared against oracle to compute efficiency.

\item \textbf{Oracle efficiency:}  $\text{Cum.~KL} / \text{Oracle~Cum.~KL}
  \times 100\%$.  Measures how close a method is to optimal.

\item \textbf{Prediction change rate:}  Fraction of steering
  experiments where the model's top-1 prediction changes.
\end{itemize}

\subsection{POMDP Agent Configuration}

The Active Inference POMDP agent is configured as follows:
\begin{itemize}
\item \textbf{State factors:} 4 importance levels $\times$
  3 layer roles $\times$ 3 causal influence levels = 36 joint states.
\item \textbf{Observation modalities:} 4 KL levels, 4 activation levels,
  3 connectivity levels.
\item \textbf{Actions:} 3 (ablation, patching, steering).
\item \textbf{Policy length:} 1 (single-step lookahead).
\item \textbf{Action selection:} stochastic (softmax over negative EFE,
  $\gamma = 16.0$).
\item \textbf{Learning:} Dirichlet updates on all observation modalities
  ($\eta = 1.0$).
\item \textbf{Inference:} variational (vanilla, as implemented
  in pymdp).
\end{itemize}

\subsection{Reproducibility}

All code is available at
\url{https://github.com/SharathSPhD/ActiveCIrcuitDiscovery}.
Colab notebooks reproduce the main experiments on a free T4 GPU.
The experiment runner supports model selection via
\texttt{-{}-model gemma|llama|both} and benchmark selection via
\texttt{-{}-experiment ioi|steering|multistep|domain|all}.
Docker images are provided for the DGX Spark environment.
Raw experiment outputs are stored in \texttt{results/} as JSON.
