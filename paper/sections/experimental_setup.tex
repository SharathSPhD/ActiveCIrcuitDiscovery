\subsection{Models and Hardware}

The framework is evaluated on two transformer architectures.
Gemma-2-2B~\cite{team2024gemma} has 26 layers, a 2304-dimensional
hidden size, and 8 attention heads; its transcoders are drawn from
GemmaScope (\texttt{mwhanna/gemma-scope-transcoders}).
Llama-3.2-1B~\cite{Dubey2024llama} has 16 layers, a 2048-dimensional
hidden size, and 32 heads with grouped-query attention; its
transcoders are from \texttt{mntss/transcoder-Llama-3.2-1B}.
Both models use the \texttt{circuit-tracer} library~\cite{Anthropic2025CT}
with the TransformerLens backend for attribution graph construction
and transcoder-level interventions.

Experiments run on an NVIDIA DGX Spark with GB10 GPU (128\,GB unified
memory, CUDA 12.8, aarch64).  Colab notebooks reproduce results on a
free T4 GPU.

\subsection{Benchmarks}

\subsubsection{IOI Circuit Recovery}

The Indirect Object Identification task, introduced by
Wang et al.~\cite{Wang2022}, tests whether the agent can identify
features causally responsible for predicting the indirect object.
Five prompts of the form
``When [A] and [B] went to the store, [A] gave the bag to \_\_''
are used, where the correct prediction is [B].  For each prompt,
the KL divergence caused by ablating each candidate feature via the
\texttt{feature\_intervention} API is measured.

\subsubsection{Multi-step Reasoning}

Three prompts requiring compositional reasoning across two or more
hops: e.g.\ ``The capital of the country where the Eiffel Tower is
located is''.

\subsubsection{Feature Steering}

Five concept prompts (Golden Gate Bridge, Eiffel Tower, Mount Everest,
Great Wall of China, Statue of Liberty).
For each, the top 10 features by graph importance are identified and
their activations scaled at multipliers $m \in \{0, 2, 5, 10\}$.
The KL divergence and whether the model's top prediction changes
are measured.

\subsubsection{Multi-Domain Benchmark}

Following the Initial Research Proposal, the framework is evaluated
across five cognitive domains with two prompts each:
geography (e.g.\ ``The capital of France is''),
mathematics (e.g.\ ``The square root of 64 is''),
science (e.g.\ ``Water is made of hydrogen and''),
logic (syllogistic reasoning), and
history (e.g.\ ``The year World War II ended was'').
This allows cross-domain comparison of circuit structure and layer
distribution.

\subsection{Baselines}

Four baselines are compared.  \emph{Random} selection draws features
uniformly at random (10 trials, results averaged).  \emph{Greedy}
selection ranks features in descending order of graph node influence
(sum of absolute adjacency weights).  The \emph{bandit} selector
combines graph importance with a decaying uncertainty bonus and
learned per-layer priors, providing a comparison point that separates
the contribution of Active Inference from simpler uncertainty
heuristics.  The \emph{oracle} selects features in descending order
of true KL divergence, an upper bound that requires all ablations
in advance.

All methods use the same \texttt{feature\_intervention} API and
KL divergence metric.  Budgets are fixed at $B=20$ interventions
per prompt.

\subsection{Metrics}

Four metrics are reported.  \emph{Mean KL per intervention} is the
average KL divergence across selected features, where higher values
indicate that the method finds more causally important features.
\emph{Cumulative KL} is the total information gained over the budget,
compared against the oracle to compute \emph{oracle efficiency},
defined as $\text{Cum.~KL} / \text{Oracle~Cum.~KL} \times 100\%$
and indicating how close a method is to optimal.  The
\emph{prediction change rate} is the fraction of steering experiments
in which the model's top-1 prediction changes.

\subsection{POMDP Agent Configuration}

The Active Inference POMDP agent uses 4 importance levels $\times$
3 layer roles $\times$ 3 causal influence levels for a total of 36
joint hidden states.  Observations comprise 4 KL levels, 4 activation
levels, and 3 connectivity levels.  The agent selects among 3 actions
(ablation, patching, steering) using a single-step lookahead policy
with stochastic selection via softmax over negative EFE
($\gamma = 16.0$).  The observation model is learned online through
Dirichlet updates on all modalities ($\eta = 1.0$), and inference
uses the vanilla variational scheme implemented in pymdp.

\subsection{Reproducibility}

All code is available at
\url{https://github.com/SharathSPhD/ActiveCIrcuitDiscovery}.
Colab notebooks reproduce the main experiments on a free T4 GPU.
The experiment runner supports model selection via
\texttt{-{}-model gemma|llama|both} and benchmark selection via
\texttt{-{}-experiment ioi|steering|multistep|domain|all}.
Docker images are provided for the DGX Spark environment.
Raw experiment outputs are stored in \texttt{results/} as JSON.
