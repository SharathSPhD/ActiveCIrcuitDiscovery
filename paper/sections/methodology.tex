This section formalises the \ACD{} framework, detailing the attribution
graph backend, the active inference-inspired feature selector, and the
intervention engine.

\subsection{Architecture Overview}

\begin{figure}[t]
\centering
\resizebox{\columnwidth}{!}{%
\input{figures/architecture}%
}
\caption{System architecture of \ACD{}. The \texttt{circuit-tracer}
  pipeline (left) extracts candidate features via EAP and pruning.
  The Active Inference Selector (right) iteratively scores, selects,
  and ablates features using an uncertainty-weighted strategy.}
\label{fig:architecture}
\end{figure}

\ACD{} consists of three layers:

\begin{enumerate}
\item \textbf{Attribution Graph Backend.} Anthropic's
  \texttt{circuit-tracer} library~\cite{Anthropic2025CT} generates
  attribution graphs via Edge Attribution Patching (EAP) with GemmaScope
  transcoders for Gemma-2-2B.  The graph contains active transcoder
  features, an adjacency matrix encoding feature interactions, and
  activation values.

\item \textbf{Active Inference Selector.}  An uncertainty-weighted
  scoring function selects the next feature to intervene on, combining
  graph-structural importance (exploitation) with per-feature uncertainty
  (exploration).  Per-layer priors are learned online from observed
  causal effects.

\item \textbf{Intervention Engine.}  Executes feature-level ablations
  and steering via the \texttt{feature\_intervention} API, which
  intervenes at the transcoder level with proper network propagation
  through the underlying TransformerLens~\cite{nanda2022transformerlens}
  model.
\end{enumerate}


\subsection{Candidate Feature Extraction}

Given a prompt, the attribution graph backend produces:
\begin{itemize}
\item Active features $\{(l_i, p_i, f_i)\}$ where $l$ is layer, $p$
  is token position, and $f$ is feature index.
\item Adjacency matrix $\mat{W} \in \mathbb{R}^{n \times n}$ encoding
  feature-to-feature attribution weights.
\item Activation values $\vect{a} \in \mathbb{R}^n$.
\end{itemize}

The graph is pruned to retain features with influence above a threshold
(default 80\%).  Each retained feature $i$ receives a normalised
importance score:
\begin{equation}
  \text{imp}(i) = \frac{\sum_j |W_{ij}| + \sum_j |W_{ji}|}
                       {\max_k \left(\sum_j |W_{kj}| + \sum_j |W_{jk}|\right)}
\end{equation}

Candidates are sampled across layers (up to $k$ per layer) to ensure
diversity.


\subsection{Active Inference Selector}

\begin{figure}[t]
\centering
\resizebox{\columnwidth}{!}{%
\input{figures/efe_pipeline}%
}
\caption{Scoring function pipeline. Each candidate receives a pragmatic
  score (graph importance $\times$ layer prior) and an epistemic bonus
  (exploration weight $\times$ uncertainty). After ablation, the
  uncertainty is zeroed and the layer prior is updated based on
  observed KL divergence.}
\label{fig:scoring}
\end{figure}

The selector scores each unobserved candidate feature $i$ as:
\begin{equation}
\label{eq:score}
  \text{score}(i) = \underbrace{\text{imp}(i) \cdot \lambda_{\ell(i)}}_{\text{pragmatic}}
  + \underbrace{u(i) \cdot \omega_e}_{\text{epistemic}}
\end{equation}

where:
\begin{itemize}
\item $\text{imp}(i) \in [0, 1]$ is the normalised graph influence.
\item $\lambda_\ell$ is a learned per-layer prior, initialised to 1.
\item $u(i) \in [0, 1]$ is the feature uncertainty, initialised to 1.
\item $\omega_e > 0$ is the exploration weight (default 2.0).
\end{itemize}

The feature with the highest score is selected:
$i^* = \arg\max_{i \notin \mathcal{O}} \text{score}(i)$.


\subsection{Belief Updating}

After ablating feature $i^*$ and observing the KL divergence
$\text{KL}_{i^*}$, the selector updates its state:

\begin{enumerate}
\item \textbf{Uncertainty reduction.}
  $u(i^*) \leftarrow 0$ (fully observed).
  For all features $j$ in the same layer:
  $u(j) \leftarrow 0.7 \cdot u(j)$ (partial transfer).
  For all features $j$ at adjacent positions:
  $u(j) \leftarrow 0.9 \cdot u(j)$.

\item \textbf{Layer prior update.}
  Let $\bar{\text{KL}}_\ell$ be the running mean KL for layer $\ell$ and
  $\bar{\text{KL}}_{\text{global}}$ be the overall mean.  Then:
  \begin{equation}
    \lambda_\ell \leftarrow 1 + 0.5 \left(
      \frac{\bar{\text{KL}}_\ell}{\bar{\text{KL}}_{\text{global}}} - 1
    \right)
  \end{equation}
  This upweights layers whose features have high causal impact and
  downweights uninformative layers.
\end{enumerate}

The pragmatic--epistemic decomposition in~\cref{eq:score} mirrors the
Expected Free Energy decomposition in active
inference~\cite{Friston2015,DaCosta2020}: the pragmatic term drives
exploitation of known high-value features, while the epistemic term
drives exploration of uncertain features.  Unlike a full POMDP agent,
the selector operates in a bandit-like setting where each feature is
intervened on at most once, making the scoring function a lightweight
but effective approximation.


\subsection{Intervention Engine}

\begin{figure}[t]
\centering
\resizebox{0.85\columnwidth}{!}{%
\input{figures/circuit_flow}%
}
\caption{Flow of a single intervention step. The selector scores
  candidates, selects the best, ablates it via
  \texttt{feature\_intervention}, and updates its uncertainty and
  layer prior based on the observed KL divergence.}
\label{fig:flow}
\end{figure}

The intervention engine implements two manipulation types via the
\texttt{feature\_intervention} API:

\textbf{Ablation:} Sets transcoder feature $(l, p, f)$ to zero:
\begin{equation}
  \text{logits}_{\text{abl}} = \text{feature\_intervention}(\text{prompt},
  [(l, p, f, 0)])
\end{equation}

\textbf{Feature Steering:} Scales activation by multiplier $m$:
\begin{equation}
  \text{logits}_{\text{steer}} = \text{feature\_intervention}(\text{prompt},
  [(l, p, f, a_i \cdot m)])
\end{equation}

where $a_i$ is the clean activation value of feature $i$.

Effect is measured via KL divergence between the clean and intervened
output distributions:
\begin{equation}
  \text{KL}_i = D_{\text{KL}}\!\left(
    \text{softmax}(\text{logits}_{\text{interv}})
    \;\|\;
    \text{softmax}(\text{logits}_{\text{clean}})
  \right)
\end{equation}

The \texttt{feature\_intervention} API correctly propagates the
intervention through the replacement model's transcoder structure,
ensuring that the measured effect reflects the true causal contribution
of the feature rather than a residual-stream approximation.
