% Results populated from real experiment runs on Gemma-2-2B and Llama-3.2-1B.
% Experiments executed on NVIDIA GB10 (DGX Spark), Feb 2026.

\subsection{IOI Circuit Recovery}

Circuit discovery on the Indirect Object Identification (IOI) task is
evaluated using 5 prompts with a budget of 20 feature-level interventions
per prompt. Each intervention ablates a single transcoder feature using
the \texttt{feature\_intervention} API and measures the resulting KL
divergence. The POMDP agent, bandit baseline, greedy ranking, random
selection, and oracle upper bound are compared.

\begin{table}[htbp]
\centering
\caption{IOI Feature Discovery: Mean KL ($\pm$ std) per Intervention}
\label{tab:ioi}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{llccc}
\toprule
\textbf{Model} & \textbf{Method} & \textbf{Mean KL} & \textbf{$\pm$ std} & \textbf{Oracle Eff.} \\
\midrule
\multirow{5}{*}{Gemma-2-2B}
 & Oracle      & ---      & ---      & 100.0\%  \\
 & Bandit      & 0.000642 & 0.000422 & \textbf{74.4\%}   \\
 & Greedy      & 0.000577 & 0.000385 & 66.9\%   \\
 & POMDP Agent & 0.000503 & 0.000392 & 58.3\%   \\
 & Random      & 0.000432 & 0.000276 & 50.1\%   \\
\midrule
\multirow{5}{*}{Llama-3.2-1B}
 & Oracle      & ---      & ---      & 100.0\%  \\
 & Bandit      & 0.008606 & 0.006910 & \textbf{88.2\%}  \\
 & Random      & 0.004905 & 0.004454 & 50.3\%   \\
 & Greedy      & 0.003982 & 0.005053 & 40.8\%   \\
 & POMDP Agent & 0.003658 & 0.005223 & 37.5\%   \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}

{\small Results averaged over 5 IOI prompts ($B=20$ interventions).
On Gemma, the POMDP agent outperforms random ($+$16.3\%); on Llama
it under-performs random ($-$25.4\%), reflecting stronger epistemic
exploration in the shallower architecture.  Standard deviations
are computed across per-prompt means.  One-sided paired $t$-tests
(POMDP vs.\ Random) are not significant ($p=0.27$ Gemma, $p=0.64$
Llama; $n=5$); larger prompt sets are needed (see Limitations).}
\end{table}

\begin{figure}[t]
\centering
\input{figures/cumulative_kl}
\caption{Cumulative KL divergence over 20 intervention steps on IOI,
  averaged across 5 prompts.  Left: Gemma-2-2B; right: Llama-3.2-1B.
  The POMDP agent (red) discovers high-impact features earlier than
  the bandit baseline (orange) and greedy ranking (blue) on Gemma,
  while Llama exhibits higher absolute KL values but a different
  method ranking (see Table~\ref{tab:ioi}).}
\label{fig:cumkl}
\end{figure}

Across all prompts, the top causal features are located in layers
24--25 (e.g., \texttt{L25\_P14\_F4717}, KL=0.0015--0.013),
consistent with late-layer name-mover circuits identified in prior
work by Wang et al.~\cite{Wang2022}.

\begin{figure}[t]
\centering
\resizebox{0.85\columnwidth}{!}{%
\input{figures/attribution_graph}%
}
\caption{Simplified attribution graphs for IOI prompts.  Left:
  Gemma-2-2B (26 layers, L0--L25); right: Llama-3.2-1B (16 layers,
  L0--L15).  Nodes represent transcoder features; colour indicates
  inferred importance (red = high).  Thick red edges trace the causal
  pathway through mid- and late-layer features.  Llama's shallower
  architecture concentrates strong attributions in early layers.
  Generated by \texttt{circuit-tracer}~\cite{Anthropic2025CT}.}
\label{fig:attribution_graph}
\end{figure}


\begin{figure}[t]
\centering
\input{figures/ioi_comparison}
\caption{Oracle efficiency across IOI and multi-step reasoning tasks.
  Left: Gemma-2-2B; right: Llama-3.2-1B.  On Gemma the bandit leads
  IOI and greedy leads multi-step, with the POMDP agent competitive
  on both.  On Llama the bandit dominates both tasks while the POMDP
  agent under-performs, reflecting the compressed state space in the
  shallower architecture.}
\label{fig:oracle_eff}
\end{figure}

\subsection{Feature Steering}

Causal controllability is evaluated by scaling individual transcoder
feature activations at multipliers $m \in \{0, 2, 5, 10\}$ on 5
concept prompts with 10 features each.

\begin{table}[htbp]
\centering
\caption{Feature Steering Results}
\label{tab:steering}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{llccc}
\toprule
\textbf{Model} & \textbf{Concept} & \textbf{$m$=5} & \textbf{$m$=10} & \textbf{Max KL} \\
\midrule
\multirow{5}{*}{Gemma-2-2B}
 & Golden Gate Br.     & 0/10  & 0/10  & 0.078  \\
 & Eiffel Tower        & 2/10  & 3/10  & 1.061  \\
 & Mount Everest       & 0/10  & 0/10  & 0.045  \\
 & Great Wall          & 3/10  & 4/10  & 3.455  \\
 & Statue of Liberty   & 0/10  & 1/10  & 0.157  \\
\midrule
\multirow{5}{*}{Llama-3.2-1B}
 & Golden Gate Br.     & 0/10  & 1/10  & 1.514  \\
 & Eiffel Tower        & 0/10  & 0/10  & 0.779  \\
 & Mount Everest       & 0/10  & 0/10  & 0.988  \\
 & Great Wall          & 2/10  & 5/10  & 0.556  \\
 & Statue of Liberty   & 0/10  & 3/10  & 1.828  \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}

{\small Cells show $n/10$ top-token prediction changes.
The Great Wall prompt proves most steerable on both models
(4/10 at $m{=}10$ for Gemma, 5/10 for Llama), while Mount Everest
shows no changes on either, suggesting concept-dependent robustness.
Total prediction changes: 8/50 for Gemma, 9/50 for Llama.}
\end{table}


\begin{figure}[t]
\centering
\input{figures/steering_heatmap}
\caption{Mean KL divergence across steering multipliers for concept
  prompts (10 features each).  Left: Gemma-2-2B; right: Llama-3.2-1B.
  Higher multipliers produce larger KL divergence on both models,
  with concept-dependent sensitivity.  Llama shows higher absolute
  KL at $m{=}10$ for some concepts, consistent with its sparser
  feature representations.}
\label{fig:steering}
\end{figure}

\subsection{Active Discovery Dynamics}

The POMDP agent maintains explicit beliefs over three hidden state
factors and updates them after each intervention. Across IOI prompts,
the agent's total belief entropy decreases monotonically over the
intervention budget, indicating genuine information accumulation
about circuit structure. The EFE values also decrease over time,
reflecting the agent's growing confidence in its circuit model.

The attribution analysis reveals several structural properties.
Gemma-2-2B activates approximately 12\,600 transcoder features per
IOI prompt, of which roughly 2\,200 survive pruning at the 80\%
influence threshold; Llama-3.2-1B activates approximately 8\,000,
with roughly 1\,600 surviving.  On Gemma, causally important features
span all 26 layers but concentrate in layers 0--6 and 24--25, whereas
on Llama the distribution is more compressed, with early layers
(0--4) dominant.  Attribution graph generation takes approximately
18\,s on Gemma and 12\,s on Llama; each
\texttt{feature\_intervention} call takes approximately 0.03\,s.


\subsection{Multi-step Reasoning}

Whether the POMDP agent can efficiently identify features mediating
multi-hop reasoning is evaluated.  Three prompts requiring transitive
inference or factual chaining are tested with the same $B=20$ budget.

\begin{table}[htbp]
\centering
\caption{Multi-step Reasoning: Feature Discovery Efficiency ($\pm$ std)}
\label{tab:multistep}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{llcccc}
\toprule
\textbf{Model} & \textbf{Method} & \textbf{Mean KL} & \textbf{$\pm$ std} & \textbf{Oracle Eff.} & \textbf{vs.\ Rand.} \\
\midrule
\multirow{5}{*}{Gemma-2-2B}
 & Oracle      & ---      & ---      & 100.0\%            & ---     \\
 & Greedy      & 0.000401 & 0.000227 & \textbf{79.4\%}    & +41.2\% \\
 & Bandit      & 0.000396 & 0.000219 & 78.4\%             & +39.4\% \\
 & POMDP Agent & 0.000370 & 0.000317 & 73.3\%             & +30.4\% \\
 & Random      & 0.000284 & 0.000179 & 56.3\%             & ---     \\
\midrule
\multirow{5}{*}{Llama-3.2-1B}
 & Oracle      & ---      & ---      & 100.0\%            & ---      \\
 & Bandit      & 0.009352 & 0.007655 & \textbf{76.4\%}    & +31.1\%  \\
 & Random      & 0.007133 & 0.005165 & 58.3\%             & ---      \\
 & Greedy      & 0.001159 & 0.000624 & 9.5\%              & $-$83.8\% \\
 & POMDP Agent & 0.000796 & 0.000265 & 6.5\%              & $-$88.8\% \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}

{\small Results averaged over 3 multi-step reasoning prompts ($B=20$).
On Gemma, greedy marginally outperforms both the bandit and POMDP
agent (79.4\% vs.\ 78.4\% vs.\ 73.3\%).  On Llama, the POMDP agent
shows very low oracle efficiency (6.5\%), dominated by the bandit.
Paired $t$-tests (POMDP vs.\ Random) are not significant ($p=0.26$
Gemma, $p=0.90$ Llama; $n=3$).}
\end{table}

\begin{figure}[t]
\centering
\input{figures/layer_distribution}
\caption{Layer distribution of top-10 causal features for multi-step
  vs.\ IOI tasks.  Left: Gemma-2-2B (Early = 0--8, Mid = 9--17,
  Late = 18--25); right: Llama-3.2-1B (Early = 0--5, Mid = 6--10,
  Late = 11--15).  Multi-step reasoning recruits early-layer features
  on both architectures; the pattern is more pronounced on Gemma.}
\label{fig:layer_dist}
\end{figure}

The top causal features for multi-step prompts concentrate in early
layers (layers 0--8), consistent with the hypothesis that multi-hop
reasoning requires input processing and entity binding in lower layers
before final output computation.  This contrasts with IOI, where
late layers (24--25) dominate.


\subsection{Multi-Domain Analysis}

\Cref{tab:domain} presents per-domain results across five cognitive
categories.  Each domain is evaluated with two prompts using the same
$B=20$ budget.

\begin{table}[htbp]
\centering
\caption{Multi-Domain Feature Discovery}
\label{tab:domain}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{llccc}
\toprule
\textbf{Model} & \textbf{Domain} & \textbf{POMDP KL} & \textbf{vs.\ Rand.} & \textbf{vs.\ Greedy} \\
\midrule
\multirow{5}{*}{Gemma}
 & Geography    & 0.000752  & $-$81.4\%  & $-$89.9\%  \\
 & Mathematics  & 0.001895  & $-$56.5\%  & +7.7\%     \\
 & Science      & 0.000512  & $-$45.4\%  & $-$44.0\%  \\
 & Logic        & 0.000191  & +9.6\%     & $-$28.3\%  \\
 & History      & 0.000992  & $-$41.8\%  & $-$64.3\%  \\
\midrule
\multirow{5}{*}{Llama}
 & Geography    & 0.039697  & +42.6\%    & $-$32.4\%  \\
 & Mathematics  & 0.053165  & +123.1\%   & $-$3.7\%   \\
 & Science      & 0.002443  & $-$22.3\%  & $-$9.5\%   \\
 & Logic        & 0.000259  & +34.5\%    & $-$9.5\%   \\
 & History      & 0.002082  & $-$64.5\%  & $-$25.2\%  \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}

{\small Negative ``vs.\ Rand.'' values indicate the POMDP agent
achieves \emph{lower} mean KL per intervention than random,
meaning it selects features with more focused causal impact.
Positive values on Llama for geography and math reflect
noisier exploration in a shallower model.}
\end{table}

\begin{figure}[t]
\centering
\input{figures/domain_layers}
\caption{Layer distribution of top-10 causal features across five
  cognitive domains.  Left: Gemma-2-2B (Early = 0--8, Mid = 9--17,
  Late = 18--25); right: Llama-3.2-1B (Early = 0--5, Mid = 6--10,
  Late = 11--15).  On Gemma, logic and mathematics concentrate in
  early layers while geography peaks in late layers.  Llama shows
  a similar early-layer dominance across most domains.}
\label{fig:domain_layers}
\end{figure}

The multi-domain analysis reveals task-dependent circuit structure:
logic and mathematics prompts recruit early-layer features
(consistent with token-level pattern matching), while geography and
history prompts rely more heavily on late layers (reflecting stored
factual knowledge retrieval).  Science prompts show a more uniform
distribution across layers.


\subsection{Cross-Model Validation (Llama-3.2-1B)}

To validate generality, all experiments are replicated on
Llama-3.2-1B (16 layers, 2048-dim) using transcoders from
\texttt{mntss/transcoder-Llama-3.2-1B}.

\begin{table}[htbp]
\centering
\caption{Cross-Model Comparison: Gemma-2-2B vs.\ Llama-3.2-1B}
\label{tab:crossmodel}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllcc}
\toprule
\textbf{Model} & \textbf{Task} & \textbf{Method} & \textbf{Mean KL} & \textbf{Oracle Eff.} \\
\midrule
\multirow{4}{*}{Gemma-2-2B}
 & IOI        & POMDP Agent & 0.000503 & 58.3\% \\
 & IOI        & Bandit      & 0.000642 & 74.4\% \\
 & Multi-step & POMDP Agent & 0.000370 & 73.3\% \\
 & Multi-step & Bandit      & 0.000396 & 78.4\% \\
\midrule
\multirow{4}{*}{Llama-3.2-1B}
 & IOI        & POMDP Agent & 0.003658 & 37.5\% \\
 & IOI        & Bandit      & 0.008606 & 88.2\% \\
 & Multi-step & POMDP Agent & 0.000796 & 6.5\%  \\
 & Multi-step & Bandit      & 0.009352 & 76.4\% \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}

{\small Budget $B=20$ on all experiments.
On Gemma, the POMDP agent outperforms random ($+$16.3\% IOI,
$+$30.4\% multi-step); on Llama it under-performs random
($-$25.4\% IOI, $-$88.8\% multi-step).  The shallower
Llama architecture (16 vs.\ 26 layers) compresses the POMDP
state space, amplifying epistemic exploration at the expense
of exploitation.  The bandit heuristic achieves consistently
high oracle efficiency on both architectures.}
\end{table}


\subsection{Efficiency Comparison}

\begin{table}[htbp]
\centering
\caption{Efficiency Improvement Over Baselines}
\label{tab:efficiency}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllcc}
\toprule
\textbf{Model} & \textbf{Task} & \textbf{Comparison} & \textbf{Improv.} & \textbf{Oracle Eff.} \\
\midrule
\multirow{3}{*}{Gemma}
 & IOI        & POMDP vs.\ Random & +16.3\%    & 58.3\%  \\
 & Multi-step & POMDP vs.\ Random & +30.4\%    & 73.3\%  \\
 & Domain     & POMDP vs.\ Random & $-$61.3\%  & ---     \\
\midrule
\multirow{3}{*}{Llama}
 & IOI        & POMDP vs.\ Random & $-$25.4\%  & 37.5\%  \\
 & Multi-step & POMDP vs.\ Random & $-$88.8\%  & 6.5\%   \\
 & Domain     & POMDP vs.\ Random & +60.4\%    & ---     \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}

{\small The POMDP agent shows mixed performance against random
selection, outperforming it on Gemma IOI/multi-step and Llama domain
tasks. The agent's epistemic drive leads to informative but
not always KL-maximising selections, reflecting the
exploration--exploitation trade-off inherent in active inference.}
\end{table}


\subsection{Hypothesis Evaluation}

\begin{table}[htbp]
\centering
\caption{Hypothesis Evaluation Summary}
\label{tab:hypothesis_eval}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccc}
\toprule
\textbf{Hypothesis} & \textbf{Criterion} & \textbf{Result} & \textbf{$p$-value} & \textbf{Outcome} \\
\midrule
H1: Efficiency  & POMDP $>$ Random (paired $t$) & +16.3\% / $-$25.4\%  & 0.27 / 0.64  & \textbf{Not rejected}  \\
H2: Causal ctrl. & Binomial $>$ 1\%             & 17/100               & $<$0.001     & \textbf{Accepted}  \\
H3: Discovery    & Oracle eff.\ $\geq 50\%$     & 58.3\% / 37.5\%      & ---          & \textbf{Partial}  \\
H4: Transfer     & Qualitative replication       & Replicated           & ---          & \textbf{Accepted}  \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}

{\small H1 results shown as Gemma / Llama.
$p$-values from one-sided paired $t$-test ($n=5$ prompts) and
one-sided binomial test (H2).}
\end{table}

\textbf{H1 (Efficiency):}  The POMDP agent achieves higher mean KL
than random on Gemma IOI ($+$16.3\%) and multi-step ($+$30.4\%),
but paired $t$-tests are not significant ($p=0.27$ and $p=0.26$,
respectively) due to the small sample sizes ($n=5$ and $n=3$).
On Llama, the POMDP agent under-performs random.
\emph{Verdict:} insufficient evidence to accept H1 at
$\alpha=0.05$; the trend is positive on Gemma but the effect
size is small relative to inter-prompt variance.

\textbf{H2 (Causal Controllability):}  Feature-level steering at
$m{=}10$ changes model predictions for 8/50 features on Gemma and
9/50 on Llama (17/100 total).  A one-sided binomial test against a
1\% chance-level baseline yields $p < 10^{-15}$.
\emph{Verdict:} H2 is accepted; transcoder features carry genuine
causal influence on both architectures.

\textbf{H3 (Discovery Quality):}  Oracle efficiency on Gemma IOI
is 58.3\% ($\pm$\,std across prompts), meeting the $\geq 50\%$
criterion.  On Llama IOI it is 37.5\%, below the threshold.
\emph{Verdict:} H3 is accepted for Gemma, not for Llama; the
shallower architecture compresses the POMDP state space and
amplifies exploration.

\textbf{H4 (Cross-Architecture Transfer):}  All four experiment types
are replicated on Llama-3.2-1B.  Qualitative findings---epistemic
exploration, belief convergence, steering effects---transfer across
architectures, although quantitative performance differs
substantially.
\emph{Verdict:} H4 is accepted at the qualitative level.

\subsection{Limitations}

Several limitations of the current evaluation should be noted.
On multi-step reasoning, the POMDP agent on Gemma performs comparably
to greedy because both focus on the same high-importance early-layer
features.  Statistical significance tests require larger prompt sets
($n \geq 30$) for reliable $p$-values, whereas the current evaluation
uses only 2--5 prompts per condition.  The Mount Everest prompt showed
no steering effects on either model, suggesting that some concepts are
more robustly distributed across features.  Finally, Llama-3.2-1B
shows lower oracle efficiency (6.5--37.5\% vs.\ 58--73\% on Gemma),
likely because fewer layers (16 vs.\ 26) compress the POMDP state
space and amplify exploration at the expense of exploitation.
