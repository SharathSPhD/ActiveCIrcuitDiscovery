Mechanistic interpretability seeks to reverse-engineer the computational
circuits within large language models, yet current methods rely on
exhaustive or heuristic search over exponentially many feature
interactions. This paper introduces \emph{Active Circuit Discovery}
(\ACD{}), a framework that combines attribution graph analysis with
active inference for efficient circuit discovery. The framework
integrates Anthropic's \texttt{circuit-tracer} library as the
attribution graph backend, using Edge Attribution Patching with
transcoders to identify active transcoder features per prompt.
A POMDP agent, implemented with \texttt{pymdp}, maintains a
multi-factor generative model of feature importance, layer role,
and causal influence, and selects interventions by minimising
Expected Free Energy. The agent learns its observation model online
through Dirichlet parameter updates, enabling principled
exploration of the circuit structure.
The framework is evaluated on two architectures, Gemma-2-2B (26 layers)
and Llama-3.2-1B (16 layers), across four settings: Indirect Object
Identification (IOI), multi-step reasoning, feature steering, and a
multi-domain benchmark spanning geography, mathematics, science, logic,
and history. With a budget of 20 interventions per prompt, the POMDP
agent identifies causally important features more efficiently than
random selection, though a simpler bandit heuristic achieves higher
immediate oracle efficiency at the cost of principled uncertainty
quantification.
Feature steering confirms causal controllability: scaling individual
features at $10\times$ activation changes predictions for a subset of
tested features.
Multi-domain analysis reveals task-dependent circuit structure: IOI
circuits concentrate in late layers, while reasoning and scientific
knowledge recruit early and middle layers.
Code, notebooks, and experiment results are publicly available.
