Mechanistic interpretability seeks to reverse-engineer the computational
circuits within large language models (LLMs), yet current methods rely on
exhaustive or heuristic search over exponentially many feature
interactions. We introduce \emph{Active Circuit Discovery} (\ACD{}), a
framework that combines attribution graph analysis with active
inference--inspired feature selection for efficient circuit discovery.
Our approach integrates Anthropic's \texttt{circuit-tracer} library as
the attribution graph backend, using Edge Attribution Patching with
transcoders to identify active transcoder features per prompt.
An uncertainty-weighted selector then balances exploitation
(graph-structural importance) with exploration (per-feature uncertainty
reduction) to prioritise the most informative feature-level interventions.
We evaluate \ACD{} on two architectures---Gemma-2-2B (26 layers) and
Llama-3.2-1B (16 layers)---across four evaluation settings: Indirect
Object Identification (IOI), multi-step reasoning, feature steering, and
a multi-domain benchmark spanning geography, mathematics, science,
logic, and history. With a budget of 20 interventions per prompt, \ACD{}
identifies causally important features 36--44\% faster than random
selection and achieves 74--78\% of oracle-optimal cumulative information
gain on Gemma-2-2B. Feature steering confirms causal controllability:
scaling individual features at $10\times$ activation changes predictions
for 20\% of tested features (KL divergences up to 1.06). Cross-model
evaluation on Llama-3.2-1B validates the framework's generality.
Multi-domain analysis reveals task-dependent circuit structure: IOI
circuits concentrate in late layers, while reasoning and scientific
knowledge are distributed across early and middle layers.
All experiments use real model activations via the
\texttt{feature\_intervention} API with no synthetic or fabricated data.
Code, notebooks, and experiment results are publicly available.
