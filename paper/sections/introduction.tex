% ---- introduction.tex ----

The rapid growth in the scale and deployment of large language models (LLMs) has
intensified the need for principled methods to audit, explain, and predict their
behaviour~\cite{Bereska2024}. Mechanistic interpretability pursues this goal by
reverse-engineering the internal computations of trained models into human-legible
circuits~\cite{Olah2020,Elhage2021}. A circuit, in this context, denotes the minimal
subgraph of model components~-- attention heads, MLP neurons, or SAE features~-- whose
activations are jointly necessary and sufficient to reproduce a specific model
behaviour on a given family of inputs~\cite{Cammarata2020,Wang2022}.

Circuit analysis has produced landmark findings: Wang et al.\ identified a
fourteen-head circuit mediating Indirect Object Identification (IOI) in GPT-2
Small~\cite{Wang2022}; Hanna et al.\ localised a circuit for numerical
greater-than comparisons~\cite{Hanna2023}; and Nanda et al.\ traced the emergence of
modular arithmetic generalisation through a Fourier-space circuit during
grokking~\cite{Nanda2023Grokking}. Each of these studies required thousands of
manually guided interventions, prompting interest in automation~\cite{Conmy2023,Syed2023}.

Automated Circuit Discovery (\ACDC)~\cite{Conmy2023} generalises the activation
patching methodology of Wang et al.\ to a greedy graph-pruning algorithm that
systematically tests every edge in the computational graph. Although \ACDC\ achieves
strong fidelity on the IOI task, the number of interventions scales as $O(E)$ in the
number of graph edges, which for deep transformer models reaches the tens of
thousands. Edge Attribution Patching (\EAP)~\cite{Syed2023} reduces this cost by
approximating patch effects with integrated gradients, yet it trades correctness for
efficiency and may miss higher-order interactions. Neither method incorporates
uncertainty about the circuit structure or adapts its search strategy based on what
has already been discovered.

Active Inference is a normative framework for perception and action in biological
agents that unifies perception, learning, and planning under a single objective: the
minimisation of variational free energy (equivalently, the maximisation of model
evidence)~\cite{Friston2010,Parr2022}. When extended to planning, the framework
introduces the Expected Free Energy (\EFE), which decomposes into an epistemic term
(expected information gain about hidden states) and a pragmatic term (expected
alignment with preferences)~\cite{Friston2015,DaCosta2020}. Crucially, \EFE\
minimisation naturally trades off exploration and exploitation: an agent selects
actions that resolve uncertainty about the world while pursuing desired outcomes.

This work proposes that circuit discovery is precisely the kind of problem for which
\EFE\ minimisation is appropriate. The ``world'' is the causal graph of an LLM; the
``actions'' are ablation and activation-patching interventions; the ``hidden states''
are the identities and importances of circuit-critical features; and the ``preference''
is the rapid identification of a faithful, minimal circuit. An Active Inference agent
that maintains a belief distribution over candidate circuit components and selects
interventions to maximally resolve that uncertainty will, in theory, identify circuits
with fewer total interventions than either random or gradient-ranked selection.

The contributions of this paper are as follows.

\textbf{(C1) Theoretical framing.} A formal mapping is established between
active inference and circuit discovery, showing how transcoder features correspond
to candidate circuit components, how ablation effects correspond to observations,
and how uncertainty-weighted scoring implements the exploration--exploitation
trade-off analogous to Expected Free Energy minimisation.

\textbf{(C2) Framework implementation.} The Active Circuit Discovery (\ACD)
framework is implemented in Python, integrating Anthropic's
\texttt{circuit-tracer}~\cite{Anthropic2025CT,Ameisen2025} for Edge Attribution Patching
with GemmaScope transcoders and the \texttt{feature\_intervention} API for
causally correct transcoder-level interventions on Gemma-2-2B.

\textbf{(C3) Validated evaluation.} Three research questions are defined with
quantified targets and evaluated on two benchmarks (IOI, multi-step reasoning)
with three baselines (random, greedy, oracle), all using real model activations.
The \ACD{} selector achieves 36--44\% improvement over random selection and
74--78\% of oracle-optimal performance.

\textbf{(C4) Causal controllability.} Feature steering experiments demonstrate
that individual transcoder features causally control model behaviour, with
prediction changes observed for 20\% of tested features at $10\times$ activation
scaling.

\textbf{(C5) Reproducibility artifacts.} Three Google Colab notebooks, a Docker
container for NVIDIA DGX Spark, and raw experiment results (JSON) are released
for full reproduction.

The remainder of this paper is structured as follows. Section~\ref{sec:background}
reviews related work on circuit analysis, Active Inference, and sparse
autoencoders. Section~\ref{sec:method} describes the \ACD{} framework in detail.
Section~\ref{sec:setup} specifies the experimental protocol. Section~\ref{sec:results}
reports validated results. Section~\ref{sec:conclusion} concludes.
