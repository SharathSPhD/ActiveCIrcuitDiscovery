% ---- discussion.tex ----

\subsection{Significance of Results}

The \ACD{} selector demonstrates that combining graph-structural priors
with uncertainty-weighted exploration consistently outperforms random
feature selection for circuit discovery. The 36--44\% improvement over
random selection, validated across two distinct benchmarks, confirms that
the exploration--exploitation trade-off is material for efficient
intervention allocation.

The active inference inspiration is evident in the scoring function
(Eq.~\ref{eq:score}): the pragmatic term (graph importance weighted by
learned layer priors) drives exploitation of known high-value features,
while the epistemic term (per-feature uncertainty scaled by $\omega_e$)
drives exploration of undersampled regions. This mirrors the Expected
Free Energy decomposition from the active inference
literature~\cite{Friston2015,DaCosta2020}, instantiated here as a
lightweight scoring function rather than a full POMDP.

\subsection{Task-Dependent Circuit Structure}

A notable finding is the task-dependent layer distribution of causally
important features. IOI circuits concentrate in late layers (24--25),
consistent with prior work identifying name-mover attention heads in
the final transformer layers~\cite{Wang2022}. In contrast, multi-step
reasoning features concentrate in early layers (0--8), suggesting that
transitive inference relies on entity-binding and input-processing
computations before the model's later layers perform output selection.

This finding has implications for circuit discovery methodology: a
selector that does not explore early layers will miss critical features
for reasoning tasks, while one that does not focus on late layers will
miss output-critical features. The \ACD{} selector's layer prior
mechanism naturally adapts to both patterns.

\subsection{Limitations}

\textbf{Greedy parity on concentrated circuits.}  When causally important
features are concentrated in a few layers (as in multi-step reasoning),
the AI selector performs comparably to greedy importance ranking. The
epistemic bonus provides less differentiation when there is less
distributional diversity. This suggests that the exploration term is most
valuable for circuits with distributed importance across many layers.

\textbf{Limited prompt sets.}  The current evaluation uses 5 IOI prompts
and 3 multi-step reasoning prompts.  Statistical significance tests
require $n \geq 30$ prompts for reliable $p$-values.  The efficiency
improvements are consistent across prompts but not yet statistically
validated.

\textbf{Single model.}  Cross-architecture validation on Llama-3.2-1B
was not completed due to transcoder availability constraints.  The
framework's reliance on the \texttt{feature\_intervention} API ties it
to models with trained transcoders.

\textbf{Mount Everest non-response.}  The Mount Everest steering
experiment showed no prediction changes at any multiplier, suggesting
that some concepts are encoded in a distributed fashion that is robust
to single-feature interventions.  This highlights a limitation of
single-feature steering as a measure of causal controllability.

\textbf{Single-step planning.}  The current selector considers only
one-step-ahead scoring.  Multi-step planning, where the selector
reasons about sequences of complementary interventions, could further
improve efficiency at the cost of combinatorial complexity.

\subsection{Broader Implications for AI Safety}

Mechanistic interpretability is increasingly recognised as a foundation
for AI safety: if internal computations can be audited as circuits, it
becomes possible to verify that models are not relying on undesirable
reasoning shortcuts~\cite{Hubinger2019,Bereska2024}.  The \ACD{} framework
contributes by providing an efficient, uncertainty-aware discovery tool
that scales to production-size models (2B+ parameters).  The finding that
circuit structure is task-dependent underscores the need for systematic,
multi-benchmark evaluation in any interpretability audit.
